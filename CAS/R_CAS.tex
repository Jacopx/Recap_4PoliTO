
\title{Recap Computer Architectures (02LSEOV)}
\author{Jacopo Nasi\\
        Computer Engineer\\
        Politecnico di Torino}
\date{I Period - 2017/2018\\\bigskip\bigskip\today}

\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{geometry}
\usepackage{indentfirst} % First line indent
\usepackage{mathtools}
\usepackage{wrapfig}
\usepackage[usenames, dvipsnames]{color}
\usepackage{float}
\usepackage{amssymb}
\usepackage{ifsym}
% Misure Documento
\geometry{ a4paper, total={170mm,257mm},left=35mm, right=35mm, top=35mm, bottom=35mm }

\begin{document}

\begin{figure}
  \centering
  \includegraphics[width=10cm]{images/polito.pdf}
\end{figure}

\maketitle

\newpage
\tableofcontents

\newpage
{\noindent \Large \textbf{License}\bigskip}

This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.\\
You are free:
\begin{itemize}
  \item \textbf{to Share}: to copy, distribute and transmit the work
  \item \textbf{to Remix}: to adapt the work
\end{itemize}
Under the following conditions:
\begin{itemize}
  \item \textbf{Attribution}: you must attribute the work in the manner specified by the author or licensor (but not in any way that suggests that they endorse you or your use of the work)
  \item \textbf{Noncommercial}: you may not use this work for commercial purposes.
  \item \textbf{Share Alike}: if you alter, transform, or build upon this work, you may distribute the resulting work only under the same or similar license to this one.
\end{itemize}

\noindent More information on the Creative Commons website (http://creativecommons.org).

\begin{figure}[h!]
  \centering
  \includegraphics[width=3cm]{images/license.png}
\end{figure}

{\noindent \Large \textbf{Acknowledgments}\bigskip}

Questo breve riepilogo non ha alcuno scopo se non quello di agevolare lo studio di me stesso, se vi fosse di aiuto siete liberi di usarlo.\\
Le fonti su cui mi sono basato sono quelle relative al corso offerto (\textbf{Computer Architectures (02LSEOV)}) dal Politecnico di Torino durante l'anno accademico 2017/2018.\\
Non mi assumo nessuna responsabilitÃ  in merito ad errori o qualsiasi altra cosa. Fatene buon uso!
\newpage

\section{Introduction Computer Design}
\subsection{Computer Evolution}
The first general-purpose computer was created in the late 40s. What now we can buy for 500\$ is equivalent (performance) to what could be bought for about \$1M in 85'.\\
During the years the performance growth was not linear, as you can see in figure \ref{fig:cpugrowth}, during the first 10 years the annual increase was around 25-30\%/year, from the late 80s to the 2000 the growth is increased around 50\%/year and, in the last few years it decrease to the 22\%. Why this change during the increase?\\
\begin{figure}[h!]
  \centering
  \includegraphics[width=\linewidth]{images/cpugrowth.png}
  \caption{CPUs Growth over years}
  \label{fig:cpugrowth}
\end{figure}
The manufacturers have found a lot of physical problem related to the creation of new products, this problem are mainly related to:
\begin{itemize}
  \item Power-Issue.
  \item Lower instruction-level parallelism.
  \item Unchanged memory lantecy.
\end{itemize}
in fact, since 2004, the major industry have changed the conceptual ways to desing processors, switching from single to multi-core architectures. We can say that, in anytime, this growth is incredible an is due to improvements in technology, microprocessor architecture and software development. Since the multi core introduction the major prefers to investe on multicore system rather than develop faster CPU.\\

\subsection{Designing}
There are 5 main market areas:
\begin{itemize}
  \item \textbf{Personal Mobile Device} (PMD): Smarthphone, tablet. They are focused in energy efficency and real-time app.
  \item \textbf{Desktop Computing}: From PC to workstation and the main pourpose is optimize the price-performance ratio.
  \item \textbf{Server}: Larger-scale and more reliable computing services.
  \item \textbf{Cluster - WAS}:Emphasis on availability, price-performance and power consumption.
  \item \textbf{Embedded Computers}: Fastest growing portion of PCs market. All special-purpose computer-based application, from cheap to high-end processors.
\end{itemize}
There are to \textbf{Classes of Parallelism}:
\begin{itemize}
  \item \textbf{Data-Level} (DLP): Many data items that can be operated on at the same.
  \item \textbf{Task-Level} (TaskLP): Many task of a work can operate independently.
\end{itemize}
The first solution allow the processor to split the data operation over multiple cores, you can for example divide an array of n elements over 4 core and, if T is the computational time needed for the entire array, the final time will be T/4 plus a little time for the reunion of the data. It split the one task on different data.\\
The TLP instead is able to manage multiple task over the same data, this is the common behaviour of the actual system (pipelining techniques).\\
There are different Parallel Architectures:
\begin{itemize}
  \item \textbf{Instruction-level} (ILP): The is modestly use the data-level parallelism.
  \item \textbf{Vector and GPU}: It exploits DLP.
  \item \textbf{Thread-level} (TLP): It exploits DLP and TaskLP.
  \item \textbf{Request-level} (RLP): Exploits parallelism among decoupled (not-related) tasks.
\end{itemize}
The designing of a new computer involve important analysis to the main pourpose of it, you need to study which attributes are important for the new machine and you need to maximizes performance and matching cost and power constraints. During the last decade the PC design took advantage of architectural and technology improvements, the performance increase is more than a factor of 15 on what would have been obtained by relying solely on technology.\\

The \textbf{Moore's Law} says that: \textit{The number of transistors that can be integrated into a single chip doubles every 18/24 months}. Until now the law has worked, as you can see in the figure \ref{fig:moore} and, probably, it will work for other time.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\linewidth]{images/moore.png}
  \caption{Transistors growth on CPUs}
  \label{fig:moore}
\end{figure}

\paragraph{Cost} During the evaluation of the IC manufacturing cost it is important not to forget the impact of yeild, the percentage of products that pass the test phase. The production process for every product undergoes an evolution which normally leads to an improvement in yield (learning curve). The cost decrease is due to yield increase. Probably the most important part of the manufacturing cost is related to the validation and testing procedures.\\

\paragraph{Other designing problem} The continuos increase of the system complexity and device integration leads to porblem with power consumption, for the Power and for the Energy (manly for portable devices). Until now the greater power consumption contribution is due to the trasnsistor switching phase, related to the physical formulas the solution applied is trying to reduce the voltage.\\
Another important factor is the \textbf{Dependability} that is the quality of the system to deliver a correct service, is traditionally very high, but it can be lowered by software or hardware bugs both during the production or in designing phase. During this years the safety-critical areas where the microprocessor have relevant importance are increased, initialy only space, avionics and nuclear, but now we have rail-road, automotive, biomedical, telecom, ecc...\\
The dependability is often measured using:
\begin{itemize}
  \item \textbf{Mean Time To Failure} (MTTF): 1 failure in one billion hours.
  \item \textbf{Mean Time Between Failures} (MTBF)
  \item \textbf{Mean Time To Repair} (MTTR)
\end{itemize}
This three measures are related by the formula: $MTBF = MTTF + MTTR$

\paragraph{Performance} they be analyzed under multiple point of view, \textit{Time between start and completion of an operation, Total amount of work done in time unit, ecc...}. The UNIX system provide 4 different values:
\begin{itemize}
  \item Elapsed time
  \item CPU Time
  \begin{itemize}
    \item User
    \item System
  \end{itemize}
\end{itemize}
The evaluation of often performed letting work a computer and observing its behavior. Unfortunately, the choice of the application severely affects the performance and is not too easy looking the result in a correct way. The main solution is using benchmarks to compare different system running the same operation and production comparable times of execution. The benchmark sets are normally composed of:
\begin{itemize}
  \item Kernels
  \item Program Fragments
  \item Applications
\end{itemize}

There are multiples solution to analyze the performance one of the most common is the \textbf{Amdahl's law} and it based to the comparisons with the older version of the same product. The speedup is calculated by this formula:
\begin{equation}
  \begin{gathered}
    Speedup = \frac{Performance_{enhancement}}{Performance_{NOenhancement}}
    \label{eq:tsoglie}
  \end{gathered}
\end{equation}
the value depends on two factors:
\begin{itemize}
  \item $Fraction_{Enhanced}$: the fraction of the computation time that take advantages of the enhancement.
  \item $Speedup_{Enhanced}$: the suze of the enhancement on the part it affects.
\end{itemize}
A more complete formula is:
\begin{equation}
  \begin{gathered}
    Speedup_{overall} = \frac{1}{(1-Fraction_{Enhanced}) + \frac{Fraction_{Enhanced}}{Speedup_{Enhanced}}}
    \label{eq:tsoglie}
  \end{gathered}
\end{equation}
an example could be useful:\\

\textit{An enhancement makes one machine 10 times faster for 40\% of the programs the machine runs. Which is the overall speedup?}\\
Fraction = 0.4, Speedup = 10.
\begin{equation}
  \begin{gathered}
    Speedup_{overall} = \frac{1}{(1-0.4) + \frac{0.4}{10}} = 1.56
    \label{eq:tsoglie}
  \end{gathered}
\end{equation}

Another important designing evaluation is measuring the time required to execute a program, the are severals approaches:
\begin{itemize}
  \item Observing the real system: Not easy to be evaluated.
  \item Simulation: It could be really expensive.
  \item CPU Equation.
\end{itemize}
the latest solution use a provided formula to evaluate the CPU time:
\begin{equation}
  \begin{gathered}
    CPU_{Time} = CLK_{Time}*\sum_{i=1}^n{CPI_{i}*IC_{i}}
    \label{eq:tsoglie}
  \end{gathered}
\end{equation}
where:
\begin{itemize}
  \item \textbf{$CPI_{i}$}: Number of clock cycles required by instruction i (depends on hardware and instr set).
  \item \textbf{$IC_{i}$}: Number of times instruction i is executed in the program (depends instruction set and compiler).
  \item \textbf{$CLK_{Time}$}: Inverse of clock frequency (depends technology).
\end{itemize}
in the pipelined processor, $CPI_{i}$ may vary for a given instruction, therefore the evaluation becomes much harder.
% END Part 1 - Introduction

\section{Instruction Set Principles}
\subsection{Introduction}
The Instruction Set Architecture (ISA) is hoe the computer is seen by the programmer or the compiler. There are different kind of design and they can be selected by different characteristics. The CPUs are often classified according to the type of their internal storage:
\begin{itemize}
  \item Stack: Is the simplest one it can't accessing memory during operations.
  \item Accumlator: Similar to 8051 can access the memory during operation.
  \item Registers
  \begin{itemize}
    \item Register-memory: Similar to 8086, have a 16-bit register.
    \item Register-Register (load-store)
    \item Memory-memory (no real cases)
  \end{itemize}
\end{itemize}
Nowadays all processors are General-Purpose Register (GPR) this because registers are faster than memoery and are easier for a compiler to use. The CPUs are also classifiable by the number of operant per ALU instruction (2 or 3) and number of memory operand per ALU.\\

\subsection{Memory}
The memory has a fundamental work in the CPU world, there are several different type of it and of course different type to how accessing it.\\
There are many different \textbf{memory addresses} that can be implemented:
\begin{itemize}
  \item \textbf{Little Endian}: Byte with lower address at the least significant position. The addresses of the data is that of the LSB.
  \item \textbf{Big Endian}: Byte with lower address at the most significant position. The addess of the data is that of the MSB.
  \item \textbf{Aligned}: Allowing only aligned accesses to memory could is a limitation in terms of performance.
  \item \textbf{Misaligned}: This solution require hardware and performance overhead.
\end{itemize}
A memory position can be accessed in different ways:
\begin{itemize}
  \item \textbf{Register}: (ADD R4, R3) when a value is in a register.
  \item \textbf{Immediate}: (ADD R4, \#3) for constants.
  \item \textbf{Displacement}: (ADD R4, 100(R1)) accessing local variables.
  \item \textbf{Deferred or Indirect}: (ADD R4, (R1)) accessing using a pointer or a computed address.
  \item \textbf{Indexed}: (ADD R3, (R1 + R2)) useful in array addressing: R1=array base, R2=index.
  \item \textbf{Direct or Absolute}: (ADD R1, (1001)) useful for accessing static data.
  \item \textbf{Indirect}: (ADD R1, @(R3)) if R3 is the addr. of a pointer p, then the mode is like \*p.
  \item \textbf{Autoincrement or decrement}: (ADD R1, (R2)$\pm$) useful for stepping through array within a loop.
\end{itemize}
Is important to choosing the correct addressing mode, one can obtain some important consequences, from reduing the number of instruction to increasing the architecture.\\
There are a lot of instruction that can be done, looking at the 80x86 frequency we can see that most most used are \textit{Load, Conditional Branch, Compare and Store} that are around the 70\% of the total operation performed.\\
The instruction set encoding depends on which instruction compose the instruction set and which addressing modes are supported. When a high number of addressing modes is supported, and address specifier is used to specified the addressing mode. When the number of addressing modes is low, they can be encoded together with the opcode. The different encoding are:
\begin{itemize}
  \item \textbf{Variable}: Any number of operands, operation with variable length, lower performance and minimum code size.
  \item \textbf{Fixed}: Fixed number of operands, need address specifier, fixed instruction length, maximum performance but larger code size.
  \item \textbf{Hybrid}: Multiple format specified by the opcode and it allows a trading-off between code size and performance.
\end{itemize}

Assembly-level programs are now produced by compilers only. The CPU designer and the compiler writer must interact and cooperate. A crucial part taken by the compiler is the optimization of the register using, it easier to solve it when the number of register is higher ($>$16).

\section{Pipelining}
\subsection{Introduction}
Pipelining is an a solution to execute multiple instructions at the same time overlapping it. The different units (also called \textit{stage} or \textit{segment}) are completing different part of different instruction in parallel. The figure \ref{fig:pipe_ex} is an example of this techniques.
\begin{figure}[h!]
  \centering
  \includegraphics[width=\linewidth]{images/pipe_ex.png}
  \caption{Pipeling example}
  \label{fig:pipe_ex}
\end{figure}
The \textbf{throughput} of a pipelined processor is the number of instructions which exit the pipeline in the time unit. All the pipeline stages are synchronized (they proceed to executing the new task all together); the necessary time for executing one step is called machine cycle and, normally, corresponds to one clock cycle. Of course the duration of a machine cycle is determined by the slowest stage. CPI means clock cycles per instruction. The ideal pipeline have all stages perfectly balanced, in this way the $TRP_{pipelined} = TRP_{unpipelined} * n$ where \textit{n} is the number of pipeline stages.

\subsection{Behaviour}
The execution of each instruction may be composed of at most five clock cycles:
\begin{itemize}
  \item \textbf{IF}: Fetch the instruction from the memory address of the PC and save it in the IR.
  \item \textbf{ID}: Decode the instruction just fetched.
  \item \textbf{EX}: Execute the instruction.
  \item \textbf{MEM}: Memory access and brach completion.
  \item \textbf{WB}: Write-back.
\end{itemize}
with the unpipelined processor all instruction require 5 CC, the only optimization to reduce the average CPI is completing the ALU instruction during the MEM cycle, hardware resources could be optimized avoiding duplications.\\
The pipelined version instead can be more powerful beacause a new instrcution is started at each clock cycle and different  resources work on different instruction at the same time. There are several consideration to keep in mind during the development of this units; at every clock cycle, each resource can be used for one purpose only, this means that:
\begin{itemize}
  \item Separate instruction and data memories must be used.
  \item The register file is used in two stages: for reading (second half of CC) in ID stage and for writing (first half od CC) in WB stage.
  \item The PC (\textit{Program Counter}) must be changed in the IF stage, What about branches?
\end{itemize}
A little view of the system behaviour in figure \ref{fig:time_evo_pipe}.
\begin{figure}[h!]
  \centering
  \includegraphics[width=\linewidth]{images/time_evo_pipe.png}
  \caption{Evolution in time of Pipeling architecture}
  \label{fig:time_evo_pipe}
\end{figure}

\paragraph{Performance} The first puorpose of this architectural type is the performance increase without making single instruction faster. The single instruction are maded slower for the overhead introduced by the pipeline control. The limitations of a pipeline come from the necessity of balanced stages and pipeling overhead (pipeline register delay and clock skew).

%\subsection{Hazards} 4_Pipeling @ Page 21


\bibliographystyle{abbrv}
\bibliography{simple}

\end{document}
